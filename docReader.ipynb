{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in ./.local/lib/python3.10/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.10/site-packages (from transformers) (1.25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.local/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.4/770.4 KB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from transformers) (3.12.2)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in ./.local/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
      "Installing collected packages: tokenizers, safetensors, regex, transformers\n",
      "Successfully installed regex-2023.6.3 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytesseract in /home/dracero/.local/lib/python3.10/site-packages (0.3.10)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /home/dracero/.local/lib/python3.10/site-packages (from pytesseract) (9.5.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/dracero/.local/lib/python3.10/site-packages (from pytesseract) (23.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pillow in /usr/lib/python3/dist-packages (9.0.1)\n",
      "Collecting pillow\n",
      "  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pillow\n",
      "Successfully installed pillow-9.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/dracero/.local/lib/python3.10/site-packages (2.0.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading torchaudio-2.0.2-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/dracero/.local/lib/python3.10/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/dracero/.local/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/dracero/.local/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: filelock in /home/dracero/.local/lib/python3.10/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/dracero/.local/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/dracero/.local/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/dracero/.local/lib/python3.10/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/dracero/.local/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/dracero/.local/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/dracero/.local/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/dracero/.local/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: jinja2 in /home/dracero/.local/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in /home/dracero/.local/lib/python3.10/site-packages (from torch) (4.6.3)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/dracero/.local/lib/python3.10/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: networkx in /home/dracero/.local/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: sympy in /home/dracero/.local/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/dracero/.local/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (59.6.0)\n",
      "Requirement already satisfied: cmake in /home/dracero/.local/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/dracero/.local/lib/python3.10/site-packages (from triton==2.0.0->torch) (16.0.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/dracero/.local/lib/python3.10/site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: numpy in /home/dracero/.local/lib/python3.10/site-packages (from torchvision) (1.25.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torchvision) (2.25.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dracero/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/dracero/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "Successfully installed torchaudio-2.0.2 torchvision-0.15.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo apt-get update\n",
    "#sudo apt-get install tesseract-ocr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dracero/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\n",
    "    \"document-question-answering\",\n",
    "    model=\"impira/layoutlm-document-qa\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.8379271626472473, 'answer': 'Moodle', 'start': 36, 'end': 36}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\n",
    "    \"canguro.jpg\",\n",
    "    \"What is the third title?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 0.981 at location [7.36, 20.37, 119.69, 95.98]\n"
     ]
    }
   ],
   "source": [
    "#Hay que probar la detección con imágenes que se cargan desde MongoDB en Base64\n",
    "#Example of object detection\n",
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"imagen.jpg\"\n",
    "image = Image.open(url)\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"hustvl/yolos-tiny\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(\"hustvl/yolos-tiny\")\n",
    "\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# convert outputs (bounding boxes and class logits) to COCO API\n",
    "target_sizes = torch.tensor([image.size[::-1]])\n",
    "results = image_processor.post_process_object_detection(outputs, threshold=0.7, target_sizes=target_sizes)[\n",
    "    0\n",
    "]\n",
    "\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "    box = [round(i, 2) for i in box.tolist()]\n",
    "    print(\n",
    "        f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
    "        f\"{round(score.item(), 3)} at location {box}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pymongo\n",
      "  Downloading pymongo-4.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (648 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m648.9/648.9 KB\u001b[0m \u001b[31m649.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0\n",
      "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.3.0 pymongo-4.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dracero/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"# Guardar la imagen en formato JPEG\\nimage.save('imagen.jpg', 'JPEG')\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Este lee la imagen de la base de datos de MongoDB en formato Base64\n",
    "import pymongo\n",
    "from bson.objectid import ObjectId\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import base64\n",
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "import torch\n",
    "\n",
    "# Conectarse a la base de datos\n",
    "client = pymongo.MongoClient(\"mongodb+srv://root:juana99@cluster0.zf9fl.mongodb.net/proctoring?retryWrites=true&w=majority\")\n",
    "db = client[\"proctoring\"]\n",
    "collection = db[\"firstphoto\"]\n",
    "\n",
    "# Recuperar el documento que contiene la imagen en formato base64\n",
    "doc_id = ObjectId(\"648e3a2ce9c4e98b61de5352\")\n",
    "doc = collection.find_one({\"_id\": doc_id})\n",
    "if doc is None:\n",
    "    print(\"No se encontró el documento con el ID especificado\")\n",
    "else:\n",
    "    base64_image = doc[\"image\"]\n",
    "\n",
    "    # Convertir la cadena a bytes y agregar caracteres \"=\" al final si es necesario\n",
    "    base64_image = base64_image.encode()\n",
    "    missing_padding = len(base64_image) % 4\n",
    "    if missing_padding != 0:\n",
    "        base64_image += b'=' * (4 - missing_padding)\n",
    "        # Decodificar el contenido base64\n",
    "    image_data = base64.b64decode(base64_image.split(b',')[1])\n",
    "    # Crear una imagen PIL desde los datos decodificados\n",
    "    image = Image.open(BytesIO(image_data))\n",
    "    # Convertir la imagen a modo RGB\n",
    "    image = image.convert('RGB')\n",
    "'''# Guardar la imagen en formato JPEG\n",
    "image.save('imagen.jpg', 'JPEG')'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected person with confidence 0.996 at location [0.38, 17.47, 115.48, 96.16]\n"
     ]
    }
   ],
   "source": [
    "# Procesar la imagen usando el código existente\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"hustvl/yolos-tiny\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(\"hustvl/yolos-tiny\")\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "# convert outputs (bounding boxes and class logits) to COCO API\n",
    "target_sizes = torch.tensor([image.size[::-1]])\n",
    "results = image_processor.post_process_object_detection(outputs, threshold=0.7, target_sizes=target_sizes)[0]\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "    box = [round(i, 2) for i in box.tolist()]\n",
    "    print(\n",
    "            f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
    "            f\"{round(score.item(), 3)} at location {box}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dracero/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"# Guardar la imagen en formato JPEG\\nimage.save('imagen.jpg', 'JPEG')\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Voy a probar acá si lee el formulario que subro por screenshot\n",
    "import pymongo\n",
    "from bson.objectid import ObjectId\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import base64\n",
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "import torch\n",
    "\n",
    "# Conectarse a la base de datos\n",
    "client = pymongo.MongoClient(\"mongodb+srv://root:juana99@cluster0.zf9fl.mongodb.net/proctoring?retryWrites=true&w=majority\")\n",
    "db = client[\"proctoring\"]\n",
    "collection = db[\"screenshot\"]\n",
    "\n",
    "# Recuperar el documento que contiene la imagen en formato base64\n",
    "doc_id = ObjectId(\"64b3281bf1ec9b2434510e3a\")\n",
    "doc = collection.find_one({\"_id\": doc_id})\n",
    "if doc is None:\n",
    "    print(\"No se encontró el documento con el ID especificado\")\n",
    "else:\n",
    "    base64_image = doc[\"image\"]\n",
    "\n",
    "    # Convertir la cadena a bytes y agregar caracteres \"=\" al final si es necesario\n",
    "    base64_image = base64_image.encode()\n",
    "    missing_padding = len(base64_image) % 4\n",
    "    if missing_padding != 0:\n",
    "        base64_image += b'=' * (4 - missing_padding)\n",
    "        # Decodificar el contenido base64\n",
    "    image_data = base64.b64decode(base64_image.split(b',')[1])\n",
    "    # Crear una imagen PIL desde los datos decodificados\n",
    "    image = Image.open(BytesIO(image_data))\n",
    "    # Convertir la imagen a modo RGB\n",
    "    image = image.convert('RGB')\n",
    "'''# Guardar la imagen en formato JPEG\n",
    "image.save('imagen.jpg', 'JPEG')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\n",
    "    \"document-question-answering\",\n",
    "    model=\"impira/layoutlm-document-qa\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.33399447798728943,\n",
       "  'answer': 'Formulario de prueba',\n",
       "  'start': 63,\n",
       "  'end': 65}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\n",
    "    image,\n",
    "    \"What is the third title?\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
